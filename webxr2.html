<!doctype html>
<html>

<head>
	<meta charset="UTF-8">
	<meta name="viewport"
		content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
	<title>Hello WebXR!</title>

	<!-- three.js -->
	<script src="https://unpkg.com/three@0.126.0/build/three.js"></script>
	<script src="https://unpkg.com/three@0.126.0/examples/js/loaders/GLTFLoader.js"></script>
</head>

<body>

	<!-- Starting an immersive WebXR session requires user interaction.
    We start this one with a simple button. -->
	<button onclick="activateXR()">Start Hello WebXR</button>
	<script>
		async function activateXR() {
			// Add a canvas element and initialize a WebGL context that is compatible with WebXR.
			const canvas = document.createElement("canvas");
			document.body.appendChild(canvas);
			const gl = canvas.getContext("webgl", { xrCompatible: true });

			// To be continued in upcoming steps.
			const scene = new THREE.Scene();

			 const light = new THREE.AmbientLight(0xffffff, 1);
    const directionalLight = new THREE.DirectionalLight(0xffffff, 0.3);
    directionalLight.position.set(10, 15, 10);

    // We want this light to cast shadow.
    directionalLight.castShadow = true;

    // Make a large plane to receive our shadows
    const planeGeometry = new THREE.PlaneGeometry(2000, 2000);
    // Rotate our plane to be parallel to the floor
    planeGeometry.rotateX(-Math.PI / 2);

    // Create a mesh with a shadow material, resulting in a mesh
    // that only renders shadows once we flip the `receiveShadow` property.
    const shadowMesh = new THREE.Mesh(planeGeometry, new THREE.ShadowMaterial({
      color: 0x111111,
      opacity: 0.2,
    }));

    // Give it a name so we can reference it later, and set `receiveShadow`
    // to true so that it can render our model's shadow.
    shadowMesh.name = 'shadowMesh';
    shadowMesh.receiveShadow = true;
    shadowMesh.position.y = 10000;

    // Add lights and shadow material to scene.
    scene.add(shadowMesh);
    scene.add(light);
    scene.add(directionalLight);

			// Set up the WebGLRenderer, which handles rendering to the session's base layer.
			const renderer = new THREE.WebGLRenderer({
				alpha: true,
				preserveDrawingBuffer: true,
				canvas: canvas,
				context: gl
			});
			renderer.autoClear = false;

			// Initialize a camera for Three.js.
			const camera = new THREE.PerspectiveCamera();
			camera.matrixAutoUpdate = false;

			// Request an immersive-ar session.
			const session = await navigator.xr.requestSession("immersive-ar", { requiredFeatures: ['hit-test'] });
			session.updateRenderState({ baseLayer: new XRWebGLLayer(session, gl) });

			// Create reference spaces.
			const referenceSpace = await session.requestReferenceSpace('local');
			const viewerSpace = await session.requestReferenceSpace('viewer');

			// Create a hit test source.
			const hitTestSource = await session.requestHitTestSource({ space: viewerSpace });

			const loader = new THREE.GLTFLoader();
			let reticle;
			loader.load("https://immersive-web.github.io/webxr-samples/media/gltf/reticle/reticle.gltf", function (gltf) {
				reticle = gltf.scene;
				reticle.visible = false;
				scene.add(reticle);
			})

			let flower;
			loader.load("https://immersive-web.github.io/webxr-samples/media/gltf/sunflower/sunflower.gltf", function (gltf) {
				flower = gltf.scene;
			});

			// Handle selection events.
			session.addEventListener("select", () => {
				if (flower && reticle.visible) {
					const clone = flower.clone();
					clone.position.copy(reticle.position);
					scene.add(clone);
				}
			});

			// Create a render loop that allows us to draw on the AR view.
			const onXRFrame = (time, frame) => {
				// Queue up the next draw request.
				session.requestAnimationFrame(onXRFrame);

				// Bind the graphics framebuffer to the baseLayer's framebuffer
				gl.bindFramebuffer(gl.FRAMEBUFFER, session.renderState.baseLayer.framebuffer)

				// Retrieve the pose of the device.
				// XRFrame.getViewerPose can return null while the session attempts to establish tracking.
				const pose = frame.getViewerPose(referenceSpace);
				if (pose) {
					// In mobile AR, we only have one view.
					const view = pose.views[0];

					const viewport = session.renderState.baseLayer.getViewport(view);
					renderer.setSize(viewport.width, viewport.height)

					// Use the view's transform matrix and projection matrix to configure the THREE.camera.
					camera.matrix.fromArray(view.transform.matrix)
					camera.projectionMatrix.fromArray(view.projectionMatrix);
					camera.updateMatrixWorld(true);


					const hitTestResults = frame.getHitTestResults(hitTestSource);
					if (hitTestResults.length > 0 && reticle) {
						const hitPose = hitTestResults[0].getPose(referenceSpace);
						reticle.visible = true;
						reticle.position.set(
							hitPose.transform.position.x,
							hitPose.transform.position.y,
							hitPose.transform.position.z
						);
						reticle.updateMatrixWorld(true);
					} else if (reticle) {
						reticle.visible = false;
					}

					// Render the scene with THREE.WebGLRenderer.
					renderer.render(scene, camera)
				}
			}
			session.requestAnimationFrame(onXRFrame);
		}
	</script>
</body>

</html>
