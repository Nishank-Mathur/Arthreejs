<!doctype html>
<html>

<head>
	<meta charset="UTF-8">
	<meta name="viewport"
		content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
	<title>WebXR</title>

	<!-- three.js -->
	<script src="https://unpkg.com/three@0.126.0/build/three.js"></script>
	<script src="https://unpkg.com/three@0.126.0/examples/js/loaders/GLTFLoader.js"></script>
</head>

<body>

	<!-- Starting an immersive WebXR session requires user interaction. -->
	<button onclick="activateXR()">Start WebXR</button>
	<script>
		async function activateXR() {
			// Add a canvas element and initialize a WebGL context that is compatible with WebXR.
			const canvas = document.createElement("canvas");
			document.body.appendChild(canvas);
			const gl = canvas.getContext("webgl", { xrCompatible: true });

			// Create a Three.js scene.
			const scene = new THREE.Scene();

			// Set up lighting.
			const light = new THREE.AmbientLight(0xffffff, 1);
			const directionalLight = new THREE.DirectionalLight(0xffffff, 0.3);
			directionalLight.position.set(10, 15, 10);
			directionalLight.castShadow = true;

			// Create a shadow receiving plane.
			const planeGeometry = new THREE.PlaneGeometry(2000, 2000);
			planeGeometry.rotateX(-Math.PI / 2);
			const shadowMesh = new THREE.Mesh(planeGeometry, new THREE.ShadowMaterial({
				color: 0x111111,
				opacity: 0.2,
			}));
			shadowMesh.name = 'shadowMesh';
			shadowMesh.receiveShadow = true;
			shadowMesh.position.y = 10000;

			// Add lights and shadow material to scene.
			scene.add(shadowMesh);
			scene.add(light);
			scene.add(directionalLight);

			// Set up the WebGLRenderer.
			const renderer = new THREE.WebGLRenderer({
				alpha: true,
				preserveDrawingBuffer: true,
				canvas: canvas,
				context: gl
			});
			renderer.autoClear = false;

			// Initialize a camera for Three.js.
			const camera = new THREE.PerspectiveCamera();
			camera.matrixAutoUpdate = false;

			// Request an immersive-ar session.
			const session = await navigator.xr.requestSession("immersive-ar", { requiredFeatures: ['hit-test'] });
			session.updateRenderState({ baseLayer: new XRWebGLLayer(session, gl) });

			// Create reference spaces.
			const referenceSpace = await session.requestReferenceSpace('local');
			const viewerSpace = await session.requestReferenceSpace('viewer');

			// Create a hit test source.
			const hitTestSource = await session.requestHitTestSource({ space: viewerSpace });

			const loader = new THREE.GLTFLoader();
			let reticle;
			loader.load("https://immersive-web.github.io/webxr-samples/media/gltf/reticle/reticle.gltf", function (gltf) {
				reticle = gltf.scene;
				reticle.visible = false;
				scene.add(reticle);
			});

			// Array of model paths
			const modelPaths = [
				"3d/1.glb",
				"3d/2.glb",
				"3d/3.glb",
				"3d/4.glb",
				"3d/car.glb",
				"3d/car2.glb",
				"3d/car3.glb"
			];

			// Index to keep track of the current model
			let modelIndex = 0;

			// Function to load the next model in the array
			function loadNextModel() {
				return new Promise((resolve, reject) => {
					loader.load(modelPaths[modelIndex], function (gltf) {
						const model = gltf.scene;
						resolve(model);
					}, undefined, function (error) {
						reject(error);
					});
				});
			}

			// Handle selection events.
			session.addEventListener("select", async () => {
				try {
					if (reticle.visible) {
						const model = await loadNextModel();
						model.position.copy(reticle.position);
						scene.add(model);

						// Update modelIndex to point to the next model
						modelIndex = (modelIndex + 1) % modelPaths.length;
					}
				} catch (error) {
					console.error('Error loading model:', error);
				}
			});

			// Create a render loop that allows us to draw on the AR view.
			const onXRFrame = (time, frame) => {
				// Queue up the next draw request.
				session.requestAnimationFrame(onXRFrame);

				// Bind the graphics framebuffer to the baseLayer's framebuffer
				gl.bindFramebuffer(gl.FRAMEBUFFER, session.renderState.baseLayer.framebuffer)

				// Retrieve the pose of the device.
				const pose = frame.getViewerPose(referenceSpace);
				if (pose) {
					// In mobile AR, we only have one view.
					const view = pose.views[0];
					const viewport = session.renderState.baseLayer.getViewport(view);
					renderer.setSize(viewport.width, viewport.height);

					// Use the view's transform matrix and projection matrix to configure the THREE.camera.
					camera.matrix.fromArray(view.transform.matrix);
					camera.projectionMatrix.fromArray(view.projectionMatrix);
					camera.updateMatrixWorld(true);

					const hitTestResults = frame.getHitTestResults(hitTestSource);
					if (hitTestResults.length > 0 && reticle) {
						const hitPose = hitTestResults[0].getPose(referenceSpace);
						reticle.visible = true;
						reticle.position.set(
							hitPose.transform.position.x,
							hitPose.transform.position.y,
							hitPose.transform.position.z
						);
						reticle.updateMatrixWorld(true);
					} else if (reticle) {
						reticle.visible = false;
					}

					// Render the scene with THREE.WebGLRenderer.
					renderer.render(scene, camera);
				}
			};

			session.requestAnimationFrame(onXRFrame);
		}
	</script>
</body>

</html>