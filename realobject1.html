<!doctype html>
<html>

<head>
	<meta charset="UTF-8">
	<meta name="viewport"
		content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
	<title>WebXR</title>
	<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
	<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
	<script src="https://unpkg.com/three@0.126.0/build/three.js"></script>
	<script src="https://unpkg.com/three@0.126.0/examples/js/loaders/GLTFLoader.js"></script>
	<script src="https://unpkg.com/three@0.126.0/examples/js/controls/OrbitControls.js"></script>
	<style>
		body {
			font-family: Arial, sans-serif;
			text-align: center;
			margin: 0;
			padding: 0;
			background-color: #f4f4f4;
			width: 100%;
			height: 100vh;
			overflow: hidden;
		}

		h1 {
			color: #333;
		}

		button {
			padding: 10px 20px;
			margin: 20px 10px;
			font-size: 16px;
		}

		#arButton {
			display: none;
			position: absolute;
			bottom: 20px;
		}

		#load3DModelButton {
			display: none;
		}

		.container {
			display: flex;
			justify-content: center;
			align-items: center;
			position: relative;
		}

		#videoElement,
		#canvas {
			margin: 10px;
			background: transparent;
			position: absolute;
			top: 0;
		}

		#canvas {
			width: 500px !important;
			height: 400px !important;
			margin: -20px;
		}

		#startButton {
			display: block;
			cursor: pointer;
		}

		.loader {
			border: 4px solid rgba(0, 0, 0, 0.1);
			border-left-color: #3498db;
			border-radius: 50%;
			width: 30px;
			height: 30px;
			animation: spin 1s linear infinite;
			position: absolute;
			top: 50%;
			left: 50%;
			transform: translate(-50%, -50%);
			display: none;
		}

		@keyframes spin {
			0% {
				transform: translate(-50%, -50%) rotate(0deg);
			}

			100% {
				transform: translate(-50%, -50%) rotate(360deg);
			}
		}

		.arbtn {
			position: absolute;
			bottom: 20px;
			padding: 12px 6px;
			border: 1px solid rgb(255, 255, 255);
			border-radius: 4px;
			background: rgb(4 34 34);
			color: rgb(255, 255, 255);
			font: 13px sans-serif;
			text-align: center;
			opacity: 0.5;
			outline: none;
			z-index: 999;
			cursor: pointer;
			left: calc(50% - 50px);
			width: 100px;
		}

		.arbtn:hover {
			opacity: 1;
		}

		#model3DContainer {
			width: 100%;
			height: 500px;
			display: flex;
		}
	</style>
</head>

<body>

	<button id="startButton">Start Object Detection</button>
	<button id="load3DModelButton">Load 3D Model</button>

	<div class="container" id="objectcontainer">
		<video id="videoElement" width="600" height="500" autoplay muted></video>
		<canvas id="canvas" width="500" height="400"></canvas>
	</div>

	<div id="model3DContainer"></div>
	<div class="loader" id="loader"></div>

	<button onclick="activateXR()" class="arbtn" id="arbtn">Start AR</button>

	<script>
		document.getElementById('objectcontainer').style.display = 'none';
		document.getElementById('arbtn').style.display = 'none';
		document.getElementById('startButton').addEventListener('click', startObjectDetection);
		document.getElementById('load3DModelButton').addEventListener('click', load3DModel);

		let modelInstance;

		async function startObjectDetection() {
			document.getElementById('objectcontainer').style.display = 'flex';
			const videoElement = document.getElementById('videoElement');
			const canvas = document.getElementById('canvas');
			const ctx = canvas.getContext('2d');

			const constraints = {
				video: { facingMode: 'user' },
				audio: false
			};

			try {
				const stream = await navigator.mediaDevices.getUserMedia(constraints);
				videoElement.srcObject = stream;

				const model = await cocoSsd.load();

				videoElement.onloadedmetadata = () => {
					canvas.width = videoElement.videoWidth;
					canvas.height = videoElement.videoHeight;
					detectFrame(videoElement, model);
				};
			} catch (error) {
				console.error('Error accessing the camera', error);
			}
		}

		async function detectFrame(video, model) {
			const predictions = await model.detect(video);
			renderPredictions(predictions);

			let personDetected = predictions.some(prediction => prediction.class === 'person');

			if (personDetected) {
				document.getElementById('load3DModelButton').style.display = 'inline-block';
				document.getElementById('startButton').style.display = 'none';
			} else {
				document.getElementById('load3DModelButton').style.display = 'none';
				document.getElementById('startButton').style.display = 'block';
			}

			requestAnimationFrame(() => detectFrame(video, model));
		}

		function renderPredictions(predictions) {
			const canvas = document.getElementById('canvas');
			const ctx = canvas.getContext('2d');
			ctx.clearRect(0, 0, canvas.width, canvas.height);

			const font = '16px sans-serif';
			ctx.font = font;
			ctx.textBaseline = 'top';

			predictions.forEach(prediction => {
				const [x, y, width, height] = prediction.bbox;
				ctx.strokeStyle = '#00FFFF';
				ctx.lineWidth = 4;
				ctx.strokeRect(x, y, width, height);

				const textWidth = ctx.measureText(prediction.class).width;
				const textHeight = parseInt(font, 10);

				ctx.fillStyle = '#00FFFF';
				ctx.fillRect(x, y, textWidth + 4, textHeight + 4);

				ctx.fillStyle = '#000000';
				ctx.fillText(prediction.class, x, y);
			});
		}

		function load3DModel() {
			document.getElementById('load3DModelButton').style.display = 'none';
			document.getElementById('objectcontainer').style.display = 'none';
			document.getElementById('arbtn').style.display = 'block';

			const container = document.getElementById('model3DContainer');
			container.innerHTML = ''; // Clear previous model

			const scene = new THREE.Scene();

			const camera = new THREE.PerspectiveCamera(70, window.innerWidth / window.innerHeight, 0.01, 2000);
			camera.position.set(2, 2, 2);

			const renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
			renderer.setPixelRatio(window.devicePixelRatio);
			renderer.setSize(window.innerWidth, window.innerHeight);
			container.appendChild(renderer.domElement);
			//document.body.appendChild(renderer.domElement);

			// Lighting
			const AmbientLight = new THREE.AmbientLight(0xffffff, 1);
			scene.add(AmbientLight);

			const DirectionalLight = new THREE.DirectionalLight(0xffffff, 1);
			DirectionalLight.position.set(1, 1, 0).normalize();
			scene.add(DirectionalLight);

			const loader = new THREE.GLTFLoader();
			loader.load('3d/person.glb', function (gltf) {
				modelInstance = gltf.scene;
				modelInstance.scale.set(0.6, 0.6, 0.6);
				scene.add(modelInstance);
				//camera.position.z = 5;
				animate();
			}, undefined, function (error) {
				console.error('An error happened', error);
			});

			// Orbit Controls
			const controls = new THREE.OrbitControls(camera, renderer.domElement);
			//controls.addEventListener('change', onXRFrame);
			/*controls.minDistance = 2;
			controls.maxDistance = 10;
			controls.target.set(0, 0, -0.2);
			controls.enableDamping = true;
			controls.dampingFactor = 0.05;*/

			function animate() {
				requestAnimationFrame(animate);
				if (modelInstance) {
					//modelInstance.rotation.y += 0.01;
				}
				renderer.render(scene, camera);
			}
		}

		async function activateXR() {
			// Add a canvas element and initialize a WebGL context that is compatible with WebXR.
			const canvas = document.createElement("canvas");
			document.body.appendChild(canvas);
			const gl = canvas.getContext("webgl", { xrCompatible: true });

			// To be continued in upcoming steps.
			const scene = new THREE.Scene();

			const light = new THREE.AmbientLight(0xffffff, 1);
			const directionalLight = new THREE.DirectionalLight(0xffffff, 0.3);
			directionalLight.position.set(10, 15, 10);

			// We want this light to cast shadow.
			directionalLight.castShadow = true;

			// Make a large plane to receive our shadows
			const planeGeometry = new THREE.PlaneGeometry(2000, 2000);
			// Rotate our plane to be parallel to the floor
			planeGeometry.rotateX(-Math.PI / 2);

			// Create a mesh with a shadow material, resulting in a mesh
			// that only renders shadows once we flip the `receiveShadow` property.
			const shadowMesh = new THREE.Mesh(planeGeometry, new THREE.ShadowMaterial({
				color: 0x111111,
				opacity: 0.2,
			}));

			// Give it a name so we can reference it later, and set `receiveShadow`
			// to true so that it can render our model's shadow.
			shadowMesh.name = 'shadowMesh';
			shadowMesh.receiveShadow = true;
			shadowMesh.position.y = 10000;

			// Add lights and shadow material to scene.
			scene.add(shadowMesh);
			scene.add(light);
			scene.add(directionalLight);

			// Set up the WebGLRenderer, which handles rendering to the session's base layer.
			const renderer = new THREE.WebGLRenderer({
				alpha: true,
				preserveDrawingBuffer: true,
				canvas: canvas,
				context: gl
			});
			renderer.autoClear = false;

			// Initialize a camera for Three.js.
			const camera = new THREE.PerspectiveCamera();
			camera.matrixAutoUpdate = false;

			// Request an immersive-ar session.
			const session = await navigator.xr.requestSession("immersive-ar", { requiredFeatures: ['hit-test'] });
			session.updateRenderState({ baseLayer: new XRWebGLLayer(session, gl) });

			// Create reference spaces.
			const referenceSpace = await session.requestReferenceSpace('local');
			const viewerSpace = await session.requestReferenceSpace('viewer');

			// Create a hit test source.
			const hitTestSource = await session.requestHitTestSource({ space: viewerSpace });

			const loader = new THREE.GLTFLoader();
			let reticle;
			loader.load("https://immersive-web.github.io/webxr-samples/media/gltf/reticle/reticle.gltf", function (gltf) {
				reticle = gltf.scene;
				reticle.visible = false;
				scene.add(reticle);
			})

			let flower;
			loader.load("3d/person.glb", function (gltf) {
				gltf.scene.traverse((child) => {
				flower = gltf.scene;
			});

			// Handle selection events.
			session.addEventListener("select", () => {
				if (flower && reticle.visible) {
					const clone = flower.clone();
					clone.position.copy(reticle.position);
					scene.add(clone);
				}
			});

			// Create a render loop that allows us to draw on the AR view.
			const onXRFrame = (time, frame) => {
				// Queue up the next draw request.
				session.requestAnimationFrame(onXRFrame);

				// Bind the graphics framebuffer to the baseLayer's framebuffer
				gl.bindFramebuffer(gl.FRAMEBUFFER, session.renderState.baseLayer.framebuffer)

				// Retrieve the pose of the device.
				// XRFrame.getViewerPose can return null while the session attempts to establish tracking.
				const pose = frame.getViewerPose(referenceSpace);
				if (pose) {
					// In mobile AR, we only have one view.
					const view = pose.views[0];

					const viewport = session.renderState.baseLayer.getViewport(view);
					renderer.setSize(viewport.width, viewport.height)

					// Use the view's transform matrix and projection matrix to configure the THREE.camera.
					camera.matrix.fromArray(view.transform.matrix)
					camera.projectionMatrix.fromArray(view.projectionMatrix);
					camera.updateMatrixWorld(true);


					const hitTestResults = frame.getHitTestResults(hitTestSource);
					if (hitTestResults.length > 0 && reticle) {
						const hitPose = hitTestResults[0].getPose(referenceSpace);
						reticle.visible = true;
						reticle.position.set(
							hitPose.transform.position.x,
							hitPose.transform.position.y,
							hitPose.transform.position.z
						);
						reticle.updateMatrixWorld(true);
					} else if (reticle) {
						reticle.visible = false;
					}

					// Render the scene with THREE.WebGLRenderer.
					renderer.render(scene, camera)
				}
			}
			session.requestAnimationFrame(onXRFrame);
		}
	</script>
</body>

</html>
